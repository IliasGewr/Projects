{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ANN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSOIjCW7UtgM"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MaxAbsScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vht_Dvm4Uu3r"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcVFqJwqUx-9"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjsp2zVsUyBU"
      },
      "source": [
        "fileDownloaded = drive.CreateFile({'id':'1a-sTBUhBEP-nIcLlxDJWGs0nmfAjS3Dl'})\n",
        "fileDownloaded2 = drive.CreateFile({'id':'1MeEWzUMXOv_be1W0XLf-pqhM_tHAvNuH'})\n",
        "fileDownloaded.GetContentFile('pulsars_test_set')\n",
        "fileDownloaded2.GetContentFile('pulsars_train_set')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "38TwBUJWUyDv",
        "outputId": "de8a5134-38d7-4d53-f3f5-53ab1210e853"
      },
      "source": [
        "df1 = pd.read_csv('pulsars_test_set')\n",
        "df1.tail(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean of the integrated profile</th>\n",
              "      <th>Standard deviation of the integrated profile</th>\n",
              "      <th>Excess kurtosis of the integrated profile</th>\n",
              "      <th>Skewness of the integrated profile</th>\n",
              "      <th>Mean of the DM-SNR curve</th>\n",
              "      <th>Standard deviation of the DM-SNR curve</th>\n",
              "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
              "      <th>Skewness of the DM-SNR curve</th>\n",
              "      <th>target_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12633</th>\n",
              "      <td>106.875000</td>\n",
              "      <td>47.571328</td>\n",
              "      <td>0.199440</td>\n",
              "      <td>0.284964</td>\n",
              "      <td>3.079431</td>\n",
              "      <td>20.984455</td>\n",
              "      <td>8.427475</td>\n",
              "      <td>78.259366</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12634</th>\n",
              "      <td>133.820312</td>\n",
              "      <td>43.478161</td>\n",
              "      <td>0.136691</td>\n",
              "      <td>0.353121</td>\n",
              "      <td>0.982441</td>\n",
              "      <td>9.486068</td>\n",
              "      <td>18.528395</td>\n",
              "      <td>444.411748</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12635</th>\n",
              "      <td>98.726562</td>\n",
              "      <td>50.407823</td>\n",
              "      <td>0.565124</td>\n",
              "      <td>0.245231</td>\n",
              "      <td>0.570234</td>\n",
              "      <td>9.011285</td>\n",
              "      <td>22.018589</td>\n",
              "      <td>561.833787</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12636</th>\n",
              "      <td>126.625000</td>\n",
              "      <td>55.721826</td>\n",
              "      <td>0.002946</td>\n",
              "      <td>-0.303218</td>\n",
              "      <td>0.534281</td>\n",
              "      <td>8.588882</td>\n",
              "      <td>23.913761</td>\n",
              "      <td>660.197035</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12637</th>\n",
              "      <td>143.671875</td>\n",
              "      <td>45.302647</td>\n",
              "      <td>-0.045769</td>\n",
              "      <td>0.353643</td>\n",
              "      <td>5.173913</td>\n",
              "      <td>26.462345</td>\n",
              "      <td>5.706651</td>\n",
              "      <td>33.802613</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12638</th>\n",
              "      <td>118.484375</td>\n",
              "      <td>50.608483</td>\n",
              "      <td>-0.029059</td>\n",
              "      <td>-0.027494</td>\n",
              "      <td>0.422241</td>\n",
              "      <td>8.086684</td>\n",
              "      <td>27.446113</td>\n",
              "      <td>830.638550</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12639</th>\n",
              "      <td>96.000000</td>\n",
              "      <td>44.193113</td>\n",
              "      <td>0.388674</td>\n",
              "      <td>0.281344</td>\n",
              "      <td>1.871237</td>\n",
              "      <td>15.833746</td>\n",
              "      <td>9.634927</td>\n",
              "      <td>104.821623</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12640</th>\n",
              "      <td>122.554688</td>\n",
              "      <td>49.485605</td>\n",
              "      <td>0.127978</td>\n",
              "      <td>0.323061</td>\n",
              "      <td>16.409699</td>\n",
              "      <td>44.626893</td>\n",
              "      <td>2.945244</td>\n",
              "      <td>8.297092</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12641</th>\n",
              "      <td>119.335938</td>\n",
              "      <td>59.935939</td>\n",
              "      <td>0.159363</td>\n",
              "      <td>-0.743025</td>\n",
              "      <td>21.430602</td>\n",
              "      <td>58.872000</td>\n",
              "      <td>2.499517</td>\n",
              "      <td>4.595173</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12642</th>\n",
              "      <td>57.062500</td>\n",
              "      <td>85.797340</td>\n",
              "      <td>1.406391</td>\n",
              "      <td>0.089520</td>\n",
              "      <td>188.306020</td>\n",
              "      <td>64.712562</td>\n",
              "      <td>-1.597527</td>\n",
              "      <td>1.429475</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Mean of the integrated profile  ...  target_class\n",
              "12633                      106.875000  ...             0\n",
              "12634                      133.820312  ...             0\n",
              "12635                       98.726562  ...             0\n",
              "12636                      126.625000  ...             0\n",
              "12637                      143.671875  ...             0\n",
              "12638                      118.484375  ...             0\n",
              "12639                       96.000000  ...             0\n",
              "12640                      122.554688  ...             0\n",
              "12641                      119.335938  ...             0\n",
              "12642                       57.062500  ...             0\n",
              "\n",
              "[10 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "-n0mhLU0UyGK",
        "outputId": "08af683f-7821-467d-c941-8fa01bccceff"
      },
      "source": [
        "df2 = pd.read_csv('pulsars_train_set')\n",
        "df2.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean of the integrated profile</th>\n",
              "      <th>Standard deviation of the integrated profile</th>\n",
              "      <th>Excess kurtosis of the integrated profile</th>\n",
              "      <th>Skewness of the integrated profile</th>\n",
              "      <th>Mean of the DM-SNR curve</th>\n",
              "      <th>Standard deviation of the DM-SNR curve</th>\n",
              "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
              "      <th>Skewness of the DM-SNR curve</th>\n",
              "      <th>target_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5250</th>\n",
              "      <td>89.453125</td>\n",
              "      <td>35.848827</td>\n",
              "      <td>0.731656</td>\n",
              "      <td>3.101474</td>\n",
              "      <td>1.450669</td>\n",
              "      <td>14.204964</td>\n",
              "      <td>11.203558</td>\n",
              "      <td>142.473878</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5251</th>\n",
              "      <td>127.070312</td>\n",
              "      <td>47.663564</td>\n",
              "      <td>0.006552</td>\n",
              "      <td>-0.123634</td>\n",
              "      <td>0.853679</td>\n",
              "      <td>11.197206</td>\n",
              "      <td>16.122702</td>\n",
              "      <td>296.507738</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5252</th>\n",
              "      <td>121.375000</td>\n",
              "      <td>53.245158</td>\n",
              "      <td>0.103772</td>\n",
              "      <td>-0.365119</td>\n",
              "      <td>1.095318</td>\n",
              "      <td>12.239976</td>\n",
              "      <td>16.258042</td>\n",
              "      <td>303.880023</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5253</th>\n",
              "      <td>136.429688</td>\n",
              "      <td>59.847421</td>\n",
              "      <td>-0.187846</td>\n",
              "      <td>-0.738123</td>\n",
              "      <td>1.296823</td>\n",
              "      <td>12.166062</td>\n",
              "      <td>15.450260</td>\n",
              "      <td>285.931022</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5254</th>\n",
              "      <td>114.507812</td>\n",
              "      <td>53.902400</td>\n",
              "      <td>0.201161</td>\n",
              "      <td>-0.024789</td>\n",
              "      <td>1.946488</td>\n",
              "      <td>13.381731</td>\n",
              "      <td>10.007967</td>\n",
              "      <td>134.238910</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Mean of the integrated profile  ...  target_class\n",
              "5250                       89.453125  ...             0\n",
              "5251                      127.070312  ...             0\n",
              "5252                      121.375000  ...             0\n",
              "5253                      136.429688  ...             0\n",
              "5254                      114.507812  ...             0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vrmxsPDvVyx"
      },
      "source": [
        "x_train = df1.drop([\"target_class\"], axis=1)\n",
        "x_train2=df1.drop([\"target_class\",], axis=1)\n",
        "x_test = df2.drop([\"target_class\",], axis=1)\n",
        "y_train = df1[\"target_class\"].values\n",
        "y_test = df2[\"target_class\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCx7X1x4UyLD"
      },
      "source": [
        "scaler =MaxAbsScaler()\n",
        "scaler.fit(x_train)\n",
        "\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "x_train2 = scaler.transform(x_train2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC8fFdNpU7_R",
        "outputId": "21ed71b1-42fc-48eb-fef8-d6e9ea54e8fd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train,y_train, test_size = 0.1, random_state = 42)\n",
        "\n",
        "print (x_train.shape, y_train.shape, x_valid.shape, y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11378, 8) (11378,) (1265, 8) (1265,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC9o7A8gU8Bm",
        "outputId": "af5258d6-c567-4344-f5d4-6d5d1f3a6ef6"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "np.random.seed(124)\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Dropout\n",
        "#Convolutional nural net\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Dense( 10, activation = \"relu\", input_shape = x_train.shape))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(20, activation = \"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense( 10, activation = \"swish\"))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1, activation = \"sigmoid\"))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(optimizer = \"adam\",\n",
        "              loss = 'BinaryCrossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(patience =20, restore_best_weights = True,monitor='val_loss')\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs = 1000, batch_size = 1016,\n",
        "                      callbacks = [early_stopping], validation_data=(x_valid, y_valid)                   \n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_36 (Dense)             (None, 11378, 10)         90        \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 11378, 10)         0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 11378, 20)         220       \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 11378, 20)         0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 11378, 10)         210       \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 11378, 10)         0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 11378, 1)          11        \n",
            "=================================================================\n",
            "Total params: 531\n",
            "Trainable params: 531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_36 (Dense)             (None, 11378, 10)         90        \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 11378, 10)         0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 11378, 20)         220       \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 11378, 20)         0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 11378, 10)         210       \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 11378, 10)         0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 11378, 1)          11        \n",
            "=================================================================\n",
            "Total params: 531\n",
            "Trainable params: 531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 11378, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 11378, 8), dtype=tf.float32, name='dense_36_input'), name='dense_36_input', description=\"created by layer 'dense_36_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 11378, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 11378, 8), dtype=tf.float32, name='dense_36_input'), name='dense_36_input', description=\"created by layer 'dense_36_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
            " 1/12 [=>............................] - ETA: 5s - loss: 0.7977 - accuracy: 0.1280WARNING:tensorflow:Model was constructed with shape (None, 11378, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 11378, 8), dtype=tf.float32, name='dense_36_input'), name='dense_36_input', description=\"created by layer 'dense_36_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 0.7784 - accuracy: 0.1601 - val_loss: 0.7309 - val_accuracy: 0.0877\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7121 - accuracy: 0.3899 - val_loss: 0.6661 - val_accuracy: 0.8917\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6478 - accuracy: 0.7449 - val_loss: 0.6026 - val_accuracy: 0.9067\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5846 - accuracy: 0.8810 - val_loss: 0.5364 - val_accuracy: 0.9067\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5199 - accuracy: 0.9021 - val_loss: 0.4663 - val_accuracy: 0.9067\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.9074 - val_loss: 0.3975 - val_accuracy: 0.9067\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.9079 - val_loss: 0.3352 - val_accuracy: 0.9067\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3354 - accuracy: 0.9077 - val_loss: 0.2794 - val_accuracy: 0.9067\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2838 - accuracy: 0.9109 - val_loss: 0.2333 - val_accuracy: 0.9067\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2410 - accuracy: 0.9169 - val_loss: 0.2013 - val_accuracy: 0.9241\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2188 - accuracy: 0.9208 - val_loss: 0.1780 - val_accuracy: 0.9375\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1901 - accuracy: 0.9348 - val_loss: 0.1601 - val_accuracy: 0.9478\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1800 - accuracy: 0.9410 - val_loss: 0.1479 - val_accuracy: 0.9502\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1549 - accuracy: 0.9520 - val_loss: 0.1395 - val_accuracy: 0.9565\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1560 - accuracy: 0.9496 - val_loss: 0.1333 - val_accuracy: 0.9589\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1424 - accuracy: 0.9573 - val_loss: 0.1286 - val_accuracy: 0.9613\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1356 - accuracy: 0.9591 - val_loss: 0.1245 - val_accuracy: 0.9628\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1320 - accuracy: 0.9614 - val_loss: 0.1206 - val_accuracy: 0.9636\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1338 - accuracy: 0.9588 - val_loss: 0.1180 - val_accuracy: 0.9636\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1263 - accuracy: 0.9628 - val_loss: 0.1149 - val_accuracy: 0.9644\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1311 - accuracy: 0.9630 - val_loss: 0.1125 - val_accuracy: 0.9652\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1222 - accuracy: 0.9643 - val_loss: 0.1109 - val_accuracy: 0.9652\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1229 - accuracy: 0.9645 - val_loss: 0.1088 - val_accuracy: 0.9676\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1199 - accuracy: 0.9653 - val_loss: 0.1076 - val_accuracy: 0.9684\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.9648 - val_loss: 0.1058 - val_accuracy: 0.9676\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1131 - accuracy: 0.9697 - val_loss: 0.1050 - val_accuracy: 0.9684\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1038 - accuracy: 0.9692 - val_loss: 0.1046 - val_accuracy: 0.9700\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.9686 - val_loss: 0.1031 - val_accuracy: 0.9700\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9723 - val_loss: 0.1045 - val_accuracy: 0.9692\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1090 - accuracy: 0.9708 - val_loss: 0.1030 - val_accuracy: 0.9700\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1013 - accuracy: 0.9715 - val_loss: 0.1024 - val_accuracy: 0.9715\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.9723 - val_loss: 0.1018 - val_accuracy: 0.9715\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1020 - accuracy: 0.9715 - val_loss: 0.1016 - val_accuracy: 0.9731\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1053 - accuracy: 0.9699 - val_loss: 0.1012 - val_accuracy: 0.9731\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9739 - val_loss: 0.1011 - val_accuracy: 0.9731\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1015 - accuracy: 0.9711 - val_loss: 0.1007 - val_accuracy: 0.9731\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9744 - val_loss: 0.1004 - val_accuracy: 0.9739\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0984 - accuracy: 0.9726 - val_loss: 0.0999 - val_accuracy: 0.9731\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0983 - accuracy: 0.9726 - val_loss: 0.1008 - val_accuracy: 0.9739\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9709 - val_loss: 0.0998 - val_accuracy: 0.9731\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.9719 - val_loss: 0.0990 - val_accuracy: 0.9723\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1085 - accuracy: 0.9697 - val_loss: 0.0990 - val_accuracy: 0.9731\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9760 - val_loss: 0.0990 - val_accuracy: 0.9731\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1008 - accuracy: 0.9723 - val_loss: 0.0993 - val_accuracy: 0.9731\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1060 - accuracy: 0.9709 - val_loss: 0.0991 - val_accuracy: 0.9731\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0994 - accuracy: 0.9724 - val_loss: 0.0991 - val_accuracy: 0.9731\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1000 - accuracy: 0.9739 - val_loss: 0.0986 - val_accuracy: 0.9723\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0940 - accuracy: 0.9750 - val_loss: 0.0983 - val_accuracy: 0.9715\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9723 - val_loss: 0.0979 - val_accuracy: 0.9723\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9749 - val_loss: 0.0986 - val_accuracy: 0.9731\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9713 - val_loss: 0.0982 - val_accuracy: 0.9739\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1019 - accuracy: 0.9709 - val_loss: 0.0980 - val_accuracy: 0.9731\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.9752 - val_loss: 0.0983 - val_accuracy: 0.9731\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1006 - accuracy: 0.9720 - val_loss: 0.0982 - val_accuracy: 0.9739\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 0.9743 - val_loss: 0.0977 - val_accuracy: 0.9731\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.9721 - val_loss: 0.0977 - val_accuracy: 0.9739\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9748 - val_loss: 0.0970 - val_accuracy: 0.9731\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9749 - val_loss: 0.0974 - val_accuracy: 0.9731\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.9751 - val_loss: 0.0974 - val_accuracy: 0.9731\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9762 - val_loss: 0.0968 - val_accuracy: 0.9731\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0968 - accuracy: 0.9738 - val_loss: 0.0968 - val_accuracy: 0.9731\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9744 - val_loss: 0.0978 - val_accuracy: 0.9739\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0947 - accuracy: 0.9737 - val_loss: 0.0972 - val_accuracy: 0.9739\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0958 - accuracy: 0.9745 - val_loss: 0.0968 - val_accuracy: 0.9731\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9732 - val_loss: 0.0968 - val_accuracy: 0.9739\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 0.9740 - val_loss: 0.0970 - val_accuracy: 0.9739\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0907 - accuracy: 0.9755 - val_loss: 0.0968 - val_accuracy: 0.9739\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0938 - accuracy: 0.9735 - val_loss: 0.0965 - val_accuracy: 0.9739\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9747 - val_loss: 0.0965 - val_accuracy: 0.9731\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0931 - accuracy: 0.9759 - val_loss: 0.0966 - val_accuracy: 0.9739\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0919 - accuracy: 0.9755 - val_loss: 0.0967 - val_accuracy: 0.9739\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0942 - accuracy: 0.9747 - val_loss: 0.0965 - val_accuracy: 0.9739\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 0.9749 - val_loss: 0.0961 - val_accuracy: 0.9739\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9747 - val_loss: 0.0957 - val_accuracy: 0.9739\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0866 - accuracy: 0.9763 - val_loss: 0.0961 - val_accuracy: 0.9731\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1002 - accuracy: 0.9725 - val_loss: 0.0963 - val_accuracy: 0.9739\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0945 - accuracy: 0.9743 - val_loss: 0.0960 - val_accuracy: 0.9739\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9756 - val_loss: 0.0960 - val_accuracy: 0.9739\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0877 - accuracy: 0.9756 - val_loss: 0.0956 - val_accuracy: 0.9747\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0954 - accuracy: 0.9728 - val_loss: 0.0955 - val_accuracy: 0.9747\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0947 - accuracy: 0.9743 - val_loss: 0.0954 - val_accuracy: 0.9747\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9762 - val_loss: 0.0956 - val_accuracy: 0.9747\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9724 - val_loss: 0.0956 - val_accuracy: 0.9739\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9744 - val_loss: 0.0954 - val_accuracy: 0.9747\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9759 - val_loss: 0.0954 - val_accuracy: 0.9747\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0888 - accuracy: 0.9756 - val_loss: 0.0953 - val_accuracy: 0.9747\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0946 - accuracy: 0.9737 - val_loss: 0.0957 - val_accuracy: 0.9747\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.9752 - val_loss: 0.0953 - val_accuracy: 0.9747\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0954 - accuracy: 0.9733 - val_loss: 0.0951 - val_accuracy: 0.9739\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.9737 - val_loss: 0.0954 - val_accuracy: 0.9747\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9767 - val_loss: 0.0952 - val_accuracy: 0.9739\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0995 - accuracy: 0.9709 - val_loss: 0.0951 - val_accuracy: 0.9747\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0923 - accuracy: 0.9749 - val_loss: 0.0951 - val_accuracy: 0.9755\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0923 - accuracy: 0.9742 - val_loss: 0.0948 - val_accuracy: 0.9739\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0928 - accuracy: 0.9761 - val_loss: 0.0947 - val_accuracy: 0.9747\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0869 - accuracy: 0.9752 - val_loss: 0.0947 - val_accuracy: 0.9747\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9754 - val_loss: 0.0946 - val_accuracy: 0.9747\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9747 - val_loss: 0.0947 - val_accuracy: 0.9747\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9739 - val_loss: 0.0944 - val_accuracy: 0.9739\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0878 - accuracy: 0.9754 - val_loss: 0.0949 - val_accuracy: 0.9755\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9754 - val_loss: 0.0944 - val_accuracy: 0.9739\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0884 - accuracy: 0.9756 - val_loss: 0.0944 - val_accuracy: 0.9747\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0895 - accuracy: 0.9749 - val_loss: 0.0944 - val_accuracy: 0.9739\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0938 - accuracy: 0.9747 - val_loss: 0.0945 - val_accuracy: 0.9739\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9747 - val_loss: 0.0946 - val_accuracy: 0.9739\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9758 - val_loss: 0.0945 - val_accuracy: 0.9747\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0873 - accuracy: 0.9747 - val_loss: 0.0944 - val_accuracy: 0.9739\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0886 - accuracy: 0.9753 - val_loss: 0.0944 - val_accuracy: 0.9747\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0888 - accuracy: 0.9758 - val_loss: 0.0943 - val_accuracy: 0.9763\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0893 - accuracy: 0.9755 - val_loss: 0.0939 - val_accuracy: 0.9747\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0929 - accuracy: 0.9748 - val_loss: 0.0939 - val_accuracy: 0.9739\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0942 - accuracy: 0.9748 - val_loss: 0.0939 - val_accuracy: 0.9739\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0895 - accuracy: 0.9751 - val_loss: 0.0939 - val_accuracy: 0.9747\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9775 - val_loss: 0.0936 - val_accuracy: 0.9763\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9747 - val_loss: 0.0933 - val_accuracy: 0.9739\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0854 - accuracy: 0.9765 - val_loss: 0.0934 - val_accuracy: 0.9739\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0877 - accuracy: 0.9754 - val_loss: 0.0931 - val_accuracy: 0.9747\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0885 - accuracy: 0.9760 - val_loss: 0.0931 - val_accuracy: 0.9747\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0885 - accuracy: 0.9758 - val_loss: 0.0933 - val_accuracy: 0.9763\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0924 - accuracy: 0.9726 - val_loss: 0.0931 - val_accuracy: 0.9747\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0846 - accuracy: 0.9768 - val_loss: 0.0932 - val_accuracy: 0.9747\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0870 - accuracy: 0.9754 - val_loss: 0.0931 - val_accuracy: 0.9747\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0916 - accuracy: 0.9745 - val_loss: 0.0932 - val_accuracy: 0.9747\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9757 - val_loss: 0.0932 - val_accuracy: 0.9763\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0853 - accuracy: 0.9751 - val_loss: 0.0930 - val_accuracy: 0.9739\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0882 - accuracy: 0.9755 - val_loss: 0.0930 - val_accuracy: 0.9763\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9762 - val_loss: 0.0931 - val_accuracy: 0.9755\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0802 - accuracy: 0.9791 - val_loss: 0.0925 - val_accuracy: 0.9763\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0880 - accuracy: 0.9764 - val_loss: 0.0921 - val_accuracy: 0.9755\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9761 - val_loss: 0.0926 - val_accuracy: 0.9755\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0811 - accuracy: 0.9760 - val_loss: 0.0927 - val_accuracy: 0.9755\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0820 - accuracy: 0.9772 - val_loss: 0.0923 - val_accuracy: 0.9747\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0822 - accuracy: 0.9765 - val_loss: 0.0926 - val_accuracy: 0.9763\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0864 - accuracy: 0.9755 - val_loss: 0.0922 - val_accuracy: 0.9755\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0853 - accuracy: 0.9763 - val_loss: 0.0921 - val_accuracy: 0.9755\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9753 - val_loss: 0.0924 - val_accuracy: 0.9755\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9771 - val_loss: 0.0926 - val_accuracy: 0.9755\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0941 - accuracy: 0.9747 - val_loss: 0.0920 - val_accuracy: 0.9747\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0863 - accuracy: 0.9766 - val_loss: 0.0922 - val_accuracy: 0.9755\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0862 - accuracy: 0.9767 - val_loss: 0.0919 - val_accuracy: 0.9755\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0854 - accuracy: 0.9754 - val_loss: 0.0916 - val_accuracy: 0.9755\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0866 - accuracy: 0.9764 - val_loss: 0.0920 - val_accuracy: 0.9755\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9768 - val_loss: 0.0919 - val_accuracy: 0.9755\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 0.9768 - val_loss: 0.0915 - val_accuracy: 0.9755\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0800 - accuracy: 0.9783 - val_loss: 0.0914 - val_accuracy: 0.9763\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9737 - val_loss: 0.0913 - val_accuracy: 0.9763\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9779 - val_loss: 0.0914 - val_accuracy: 0.9755\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.9771 - val_loss: 0.0912 - val_accuracy: 0.9755\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0893 - accuracy: 0.9753 - val_loss: 0.0910 - val_accuracy: 0.9755\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0871 - accuracy: 0.9742 - val_loss: 0.0911 - val_accuracy: 0.9755\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 0.9773 - val_loss: 0.0915 - val_accuracy: 0.9755\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.9760 - val_loss: 0.0913 - val_accuracy: 0.9763\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9740 - val_loss: 0.0917 - val_accuracy: 0.9755\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0894 - accuracy: 0.9754 - val_loss: 0.0911 - val_accuracy: 0.9755\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9777 - val_loss: 0.0915 - val_accuracy: 0.9755\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0841 - accuracy: 0.9749 - val_loss: 0.0911 - val_accuracy: 0.9747\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0811 - accuracy: 0.9757 - val_loss: 0.0910 - val_accuracy: 0.9755\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9760 - val_loss: 0.0909 - val_accuracy: 0.9755\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9781 - val_loss: 0.0907 - val_accuracy: 0.9755\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.9768 - val_loss: 0.0905 - val_accuracy: 0.9755\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0865 - accuracy: 0.9755 - val_loss: 0.0905 - val_accuracy: 0.9755\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9783 - val_loss: 0.0914 - val_accuracy: 0.9755\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0812 - accuracy: 0.9768 - val_loss: 0.0908 - val_accuracy: 0.9755\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9760 - val_loss: 0.0907 - val_accuracy: 0.9763\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9755 - val_loss: 0.0908 - val_accuracy: 0.9755\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9769 - val_loss: 0.0903 - val_accuracy: 0.9755\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0772 - accuracy: 0.9768 - val_loss: 0.0905 - val_accuracy: 0.9763\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9759 - val_loss: 0.0904 - val_accuracy: 0.9755\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9743 - val_loss: 0.0905 - val_accuracy: 0.9755\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9775 - val_loss: 0.0907 - val_accuracy: 0.9763\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9764 - val_loss: 0.0910 - val_accuracy: 0.9763\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0902 - accuracy: 0.9743 - val_loss: 0.0908 - val_accuracy: 0.9763\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9759 - val_loss: 0.0907 - val_accuracy: 0.9755\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0796 - accuracy: 0.9764 - val_loss: 0.0907 - val_accuracy: 0.9763\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0827 - accuracy: 0.9754 - val_loss: 0.0901 - val_accuracy: 0.9755\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0799 - accuracy: 0.9783 - val_loss: 0.0901 - val_accuracy: 0.9763\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9768 - val_loss: 0.0897 - val_accuracy: 0.9755\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.9773 - val_loss: 0.0897 - val_accuracy: 0.9755\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9762 - val_loss: 0.0900 - val_accuracy: 0.9763\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0875 - accuracy: 0.9742 - val_loss: 0.0895 - val_accuracy: 0.9755\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9758 - val_loss: 0.0900 - val_accuracy: 0.9763\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9766 - val_loss: 0.0899 - val_accuracy: 0.9763\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9776 - val_loss: 0.0895 - val_accuracy: 0.9763\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9764 - val_loss: 0.0893 - val_accuracy: 0.9763\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0817 - accuracy: 0.9767 - val_loss: 0.0892 - val_accuracy: 0.9755\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9770 - val_loss: 0.0897 - val_accuracy: 0.9763\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 0.9769 - val_loss: 0.0891 - val_accuracy: 0.9755\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9750 - val_loss: 0.0892 - val_accuracy: 0.9755\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9758 - val_loss: 0.0894 - val_accuracy: 0.9755\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9785 - val_loss: 0.0893 - val_accuracy: 0.9763\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0857 - accuracy: 0.9755 - val_loss: 0.0893 - val_accuracy: 0.9763\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0813 - accuracy: 0.9752 - val_loss: 0.0892 - val_accuracy: 0.9755\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9780 - val_loss: 0.0891 - val_accuracy: 0.9755\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0801 - accuracy: 0.9783 - val_loss: 0.0894 - val_accuracy: 0.9763\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0827 - accuracy: 0.9771 - val_loss: 0.0889 - val_accuracy: 0.9755\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9765 - val_loss: 0.0887 - val_accuracy: 0.9763\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 0.9758 - val_loss: 0.0884 - val_accuracy: 0.9763\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9774 - val_loss: 0.0884 - val_accuracy: 0.9771\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9782 - val_loss: 0.0882 - val_accuracy: 0.9771\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0811 - accuracy: 0.9768 - val_loss: 0.0882 - val_accuracy: 0.9763\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0803 - accuracy: 0.9772 - val_loss: 0.0880 - val_accuracy: 0.9763\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 0.9765 - val_loss: 0.0879 - val_accuracy: 0.9763\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0799 - accuracy: 0.9771 - val_loss: 0.0882 - val_accuracy: 0.9763\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0739 - accuracy: 0.9785 - val_loss: 0.0881 - val_accuracy: 0.9771\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 0.9748 - val_loss: 0.0881 - val_accuracy: 0.9763\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0777 - accuracy: 0.9775 - val_loss: 0.0881 - val_accuracy: 0.9763\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9763 - val_loss: 0.0879 - val_accuracy: 0.9763\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9768 - val_loss: 0.0877 - val_accuracy: 0.9763\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0837 - accuracy: 0.9768 - val_loss: 0.0877 - val_accuracy: 0.9763\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9777 - val_loss: 0.0875 - val_accuracy: 0.9763\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9783 - val_loss: 0.0872 - val_accuracy: 0.9763\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9771 - val_loss: 0.0874 - val_accuracy: 0.9763\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0773 - accuracy: 0.9772 - val_loss: 0.0875 - val_accuracy: 0.9771\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0796 - accuracy: 0.9768 - val_loss: 0.0875 - val_accuracy: 0.9771\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0686 - accuracy: 0.9799 - val_loss: 0.0874 - val_accuracy: 0.9763\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.9775 - val_loss: 0.0870 - val_accuracy: 0.9763\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9793 - val_loss: 0.0867 - val_accuracy: 0.9763\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9779 - val_loss: 0.0869 - val_accuracy: 0.9779\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.9783 - val_loss: 0.0868 - val_accuracy: 0.9779\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.9782 - val_loss: 0.0867 - val_accuracy: 0.9771\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0820 - accuracy: 0.9783 - val_loss: 0.0867 - val_accuracy: 0.9771\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9776 - val_loss: 0.0868 - val_accuracy: 0.9771\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0781 - accuracy: 0.9776 - val_loss: 0.0871 - val_accuracy: 0.9771\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0768 - accuracy: 0.9797 - val_loss: 0.0869 - val_accuracy: 0.9763\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0783 - accuracy: 0.9774 - val_loss: 0.0866 - val_accuracy: 0.9771\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0771 - accuracy: 0.9777 - val_loss: 0.0867 - val_accuracy: 0.9771\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9774 - val_loss: 0.0869 - val_accuracy: 0.9771\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9757 - val_loss: 0.0866 - val_accuracy: 0.9763\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9764 - val_loss: 0.0867 - val_accuracy: 0.9771\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9759 - val_loss: 0.0868 - val_accuracy: 0.9771\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0769 - accuracy: 0.9761 - val_loss: 0.0864 - val_accuracy: 0.9779\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0771 - accuracy: 0.9767 - val_loss: 0.0860 - val_accuracy: 0.9771\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9785 - val_loss: 0.0863 - val_accuracy: 0.9771\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9772 - val_loss: 0.0862 - val_accuracy: 0.9771\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9789 - val_loss: 0.0865 - val_accuracy: 0.9771\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9756 - val_loss: 0.0860 - val_accuracy: 0.9779\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9776 - val_loss: 0.0862 - val_accuracy: 0.9779\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0798 - accuracy: 0.9765 - val_loss: 0.0858 - val_accuracy: 0.9763\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9783 - val_loss: 0.0857 - val_accuracy: 0.9771\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9790 - val_loss: 0.0860 - val_accuracy: 0.9771\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0736 - accuracy: 0.9788 - val_loss: 0.0858 - val_accuracy: 0.9771\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0861 - accuracy: 0.9746 - val_loss: 0.0855 - val_accuracy: 0.9779\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9775 - val_loss: 0.0857 - val_accuracy: 0.9779\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9788 - val_loss: 0.0859 - val_accuracy: 0.9779\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0736 - accuracy: 0.9790 - val_loss: 0.0850 - val_accuracy: 0.9779\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0813 - accuracy: 0.9759 - val_loss: 0.0850 - val_accuracy: 0.9779\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9773 - val_loss: 0.0850 - val_accuracy: 0.9779\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9791 - val_loss: 0.0851 - val_accuracy: 0.9779\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0739 - accuracy: 0.9795 - val_loss: 0.0850 - val_accuracy: 0.9771\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9747 - val_loss: 0.0850 - val_accuracy: 0.9779\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9780 - val_loss: 0.0853 - val_accuracy: 0.9779\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0767 - accuracy: 0.9787 - val_loss: 0.0849 - val_accuracy: 0.9779\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9771 - val_loss: 0.0848 - val_accuracy: 0.9779\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9792 - val_loss: 0.0851 - val_accuracy: 0.9771\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9765 - val_loss: 0.0848 - val_accuracy: 0.9779\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9785 - val_loss: 0.0850 - val_accuracy: 0.9779\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9788 - val_loss: 0.0845 - val_accuracy: 0.9779\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9784 - val_loss: 0.0843 - val_accuracy: 0.9771\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9771 - val_loss: 0.0843 - val_accuracy: 0.9771\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9765 - val_loss: 0.0846 - val_accuracy: 0.9771\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0799 - accuracy: 0.9785 - val_loss: 0.0840 - val_accuracy: 0.9779\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0751 - accuracy: 0.9794 - val_loss: 0.0843 - val_accuracy: 0.9779\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9790 - val_loss: 0.0842 - val_accuracy: 0.9779\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9792 - val_loss: 0.0844 - val_accuracy: 0.9779\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9785 - val_loss: 0.0842 - val_accuracy: 0.9779\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9775 - val_loss: 0.0841 - val_accuracy: 0.9779\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0731 - accuracy: 0.9779 - val_loss: 0.0840 - val_accuracy: 0.9779\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0728 - accuracy: 0.9777 - val_loss: 0.0839 - val_accuracy: 0.9779\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0795 - accuracy: 0.9771 - val_loss: 0.0836 - val_accuracy: 0.9779\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0767 - accuracy: 0.9778 - val_loss: 0.0838 - val_accuracy: 0.9771\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9772 - val_loss: 0.0836 - val_accuracy: 0.9771\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9776 - val_loss: 0.0839 - val_accuracy: 0.9771\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9756 - val_loss: 0.0834 - val_accuracy: 0.9771\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0753 - accuracy: 0.9778 - val_loss: 0.0841 - val_accuracy: 0.9771\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9775 - val_loss: 0.0837 - val_accuracy: 0.9771\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0781 - accuracy: 0.9779 - val_loss: 0.0834 - val_accuracy: 0.9771\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0719 - accuracy: 0.9801 - val_loss: 0.0838 - val_accuracy: 0.9771\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0745 - accuracy: 0.9792 - val_loss: 0.0832 - val_accuracy: 0.9771\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0767 - accuracy: 0.9794 - val_loss: 0.0830 - val_accuracy: 0.9755\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9781 - val_loss: 0.0838 - val_accuracy: 0.9771\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0779 - accuracy: 0.9778 - val_loss: 0.0832 - val_accuracy: 0.9763\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9781 - val_loss: 0.0838 - val_accuracy: 0.9771\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0706 - accuracy: 0.9804 - val_loss: 0.0830 - val_accuracy: 0.9763\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9782 - val_loss: 0.0830 - val_accuracy: 0.9763\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0755 - accuracy: 0.9782 - val_loss: 0.0843 - val_accuracy: 0.9771\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9784 - val_loss: 0.0830 - val_accuracy: 0.9779\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0768 - accuracy: 0.9789 - val_loss: 0.0826 - val_accuracy: 0.9771\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9785 - val_loss: 0.0830 - val_accuracy: 0.9771\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0781 - accuracy: 0.9768 - val_loss: 0.0828 - val_accuracy: 0.9771\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9758 - val_loss: 0.0828 - val_accuracy: 0.9771\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0742 - accuracy: 0.9788 - val_loss: 0.0829 - val_accuracy: 0.9771\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0774 - accuracy: 0.9775 - val_loss: 0.0824 - val_accuracy: 0.9771\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0763 - accuracy: 0.9779 - val_loss: 0.0821 - val_accuracy: 0.9771\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0717 - accuracy: 0.9777 - val_loss: 0.0820 - val_accuracy: 0.9779\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0716 - accuracy: 0.9788 - val_loss: 0.0824 - val_accuracy: 0.9771\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9778 - val_loss: 0.0819 - val_accuracy: 0.9771\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0753 - accuracy: 0.9780 - val_loss: 0.0823 - val_accuracy: 0.9771\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9782 - val_loss: 0.0820 - val_accuracy: 0.9771\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0733 - accuracy: 0.9797 - val_loss: 0.0826 - val_accuracy: 0.9763\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0753 - accuracy: 0.9780 - val_loss: 0.0814 - val_accuracy: 0.9771\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0722 - accuracy: 0.9799 - val_loss: 0.0816 - val_accuracy: 0.9779\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9797 - val_loss: 0.0816 - val_accuracy: 0.9771\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9761 - val_loss: 0.0824 - val_accuracy: 0.9771\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9790 - val_loss: 0.0817 - val_accuracy: 0.9779\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9782 - val_loss: 0.0814 - val_accuracy: 0.9779\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0770 - accuracy: 0.9778 - val_loss: 0.0823 - val_accuracy: 0.9771\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0744 - accuracy: 0.9793 - val_loss: 0.0810 - val_accuracy: 0.9763\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0751 - accuracy: 0.9786 - val_loss: 0.0818 - val_accuracy: 0.9771\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9793 - val_loss: 0.0817 - val_accuracy: 0.9763\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0747 - accuracy: 0.9781 - val_loss: 0.0816 - val_accuracy: 0.9771\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9791 - val_loss: 0.0817 - val_accuracy: 0.9771\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9775 - val_loss: 0.0816 - val_accuracy: 0.9771\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0732 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9771\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0694 - accuracy: 0.9790 - val_loss: 0.0806 - val_accuracy: 0.9771\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0715 - accuracy: 0.9799 - val_loss: 0.0808 - val_accuracy: 0.9771\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9797 - val_loss: 0.0814 - val_accuracy: 0.9771\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9781 - val_loss: 0.0814 - val_accuracy: 0.9763\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0722 - accuracy: 0.9786 - val_loss: 0.0820 - val_accuracy: 0.9771\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0767 - accuracy: 0.9780 - val_loss: 0.0811 - val_accuracy: 0.9779\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0730 - accuracy: 0.9794 - val_loss: 0.0810 - val_accuracy: 0.9779\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9784 - val_loss: 0.0806 - val_accuracy: 0.9779\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0768 - accuracy: 0.9785 - val_loss: 0.0807 - val_accuracy: 0.9771\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9792 - val_loss: 0.0808 - val_accuracy: 0.9771\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 0.9803 - val_loss: 0.0807 - val_accuracy: 0.9771\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0743 - accuracy: 0.9781 - val_loss: 0.0809 - val_accuracy: 0.9779\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0772 - accuracy: 0.9775 - val_loss: 0.0807 - val_accuracy: 0.9763\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9789 - val_loss: 0.0811 - val_accuracy: 0.9763\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9797 - val_loss: 0.0811 - val_accuracy: 0.9771\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9802 - val_loss: 0.0817 - val_accuracy: 0.9763\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9801 - val_loss: 0.0807 - val_accuracy: 0.9763\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9798 - val_loss: 0.0808 - val_accuracy: 0.9771\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0745 - accuracy: 0.9783 - val_loss: 0.0809 - val_accuracy: 0.9771\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9787 - val_loss: 0.0811 - val_accuracy: 0.9763\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0694 - accuracy: 0.9798 - val_loss: 0.0805 - val_accuracy: 0.9771\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0771 - accuracy: 0.9777 - val_loss: 0.0806 - val_accuracy: 0.9755\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9773 - val_loss: 0.0809 - val_accuracy: 0.9771\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9790 - val_loss: 0.0807 - val_accuracy: 0.9763\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0692 - accuracy: 0.9792 - val_loss: 0.0799 - val_accuracy: 0.9771\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0724 - accuracy: 0.9800 - val_loss: 0.0801 - val_accuracy: 0.9763\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9794 - val_loss: 0.0804 - val_accuracy: 0.9771\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0704 - accuracy: 0.9796 - val_loss: 0.0803 - val_accuracy: 0.9763\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9790 - val_loss: 0.0802 - val_accuracy: 0.9779\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9781 - val_loss: 0.0806 - val_accuracy: 0.9771\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0755 - accuracy: 0.9790 - val_loss: 0.0809 - val_accuracy: 0.9763\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9783 - val_loss: 0.0800 - val_accuracy: 0.9779\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0704 - accuracy: 0.9800 - val_loss: 0.0803 - val_accuracy: 0.9771\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9784 - val_loss: 0.0808 - val_accuracy: 0.9771\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9796 - val_loss: 0.0802 - val_accuracy: 0.9755\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0774 - accuracy: 0.9784 - val_loss: 0.0801 - val_accuracy: 0.9755\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0699 - accuracy: 0.9809 - val_loss: 0.0812 - val_accuracy: 0.9763\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9805 - val_loss: 0.0799 - val_accuracy: 0.9779\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9785 - val_loss: 0.0802 - val_accuracy: 0.9771\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9793 - val_loss: 0.0801 - val_accuracy: 0.9771\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9808 - val_loss: 0.0802 - val_accuracy: 0.9755\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9800 - val_loss: 0.0801 - val_accuracy: 0.9771\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0755 - accuracy: 0.9772 - val_loss: 0.0796 - val_accuracy: 0.9779\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0764 - accuracy: 0.9780 - val_loss: 0.0805 - val_accuracy: 0.9771\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9783 - val_loss: 0.0802 - val_accuracy: 0.9755\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0754 - accuracy: 0.9796 - val_loss: 0.0801 - val_accuracy: 0.9755\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0744 - accuracy: 0.9781 - val_loss: 0.0798 - val_accuracy: 0.9771\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9785 - val_loss: 0.0796 - val_accuracy: 0.9771\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9787 - val_loss: 0.0800 - val_accuracy: 0.9755\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0711 - accuracy: 0.9797 - val_loss: 0.0794 - val_accuracy: 0.9779\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0742 - accuracy: 0.9785 - val_loss: 0.0795 - val_accuracy: 0.9771\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0720 - accuracy: 0.9790 - val_loss: 0.0794 - val_accuracy: 0.9763\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0696 - accuracy: 0.9796 - val_loss: 0.0798 - val_accuracy: 0.9771\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9794 - val_loss: 0.0796 - val_accuracy: 0.9771\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9794 - val_loss: 0.0793 - val_accuracy: 0.9779\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0710 - accuracy: 0.9811 - val_loss: 0.0796 - val_accuracy: 0.9763\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9797 - val_loss: 0.0792 - val_accuracy: 0.9779\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9802 - val_loss: 0.0795 - val_accuracy: 0.9771\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0686 - accuracy: 0.9808 - val_loss: 0.0794 - val_accuracy: 0.9779\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0722 - accuracy: 0.9784 - val_loss: 0.0789 - val_accuracy: 0.9779\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0714 - accuracy: 0.9804 - val_loss: 0.0798 - val_accuracy: 0.9763\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0745 - accuracy: 0.9813 - val_loss: 0.0793 - val_accuracy: 0.9779\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9804 - val_loss: 0.0792 - val_accuracy: 0.9779\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0703 - accuracy: 0.9797 - val_loss: 0.0794 - val_accuracy: 0.9779\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9785 - val_loss: 0.0789 - val_accuracy: 0.9771\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0750 - accuracy: 0.9784 - val_loss: 0.0789 - val_accuracy: 0.9779\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0771 - accuracy: 0.9771 - val_loss: 0.0790 - val_accuracy: 0.9779\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9774 - val_loss: 0.0794 - val_accuracy: 0.9779\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9806 - val_loss: 0.0791 - val_accuracy: 0.9779\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0716 - accuracy: 0.9790 - val_loss: 0.0788 - val_accuracy: 0.9779\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9785 - val_loss: 0.0787 - val_accuracy: 0.9779\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9782 - val_loss: 0.0788 - val_accuracy: 0.9779\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0733 - accuracy: 0.9790 - val_loss: 0.0790 - val_accuracy: 0.9771\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.9757 - val_loss: 0.0788 - val_accuracy: 0.9779\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0767 - accuracy: 0.9783 - val_loss: 0.0789 - val_accuracy: 0.9779\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0744 - accuracy: 0.9806 - val_loss: 0.0791 - val_accuracy: 0.9779\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0738 - accuracy: 0.9792 - val_loss: 0.0795 - val_accuracy: 0.9771\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0736 - accuracy: 0.9788 - val_loss: 0.0790 - val_accuracy: 0.9779\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 0.9809 - val_loss: 0.0790 - val_accuracy: 0.9771\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9784 - val_loss: 0.0790 - val_accuracy: 0.9747\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.9791 - val_loss: 0.0789 - val_accuracy: 0.9779\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0730 - accuracy: 0.9784 - val_loss: 0.0790 - val_accuracy: 0.9771\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9768 - val_loss: 0.0788 - val_accuracy: 0.9779\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9786 - val_loss: 0.0790 - val_accuracy: 0.9779\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.9801 - val_loss: 0.0785 - val_accuracy: 0.9779\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0713 - accuracy: 0.9787 - val_loss: 0.0787 - val_accuracy: 0.9779\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9774 - val_loss: 0.0792 - val_accuracy: 0.9779\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9792 - val_loss: 0.0794 - val_accuracy: 0.9763\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0711 - accuracy: 0.9802 - val_loss: 0.0786 - val_accuracy: 0.9779\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9787 - val_loss: 0.0782 - val_accuracy: 0.9771\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0720 - accuracy: 0.9787 - val_loss: 0.0786 - val_accuracy: 0.9771\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0697 - accuracy: 0.9807 - val_loss: 0.0784 - val_accuracy: 0.9779\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0717 - accuracy: 0.9788 - val_loss: 0.0784 - val_accuracy: 0.9779\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0716 - accuracy: 0.9794 - val_loss: 0.0781 - val_accuracy: 0.9763\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0699 - accuracy: 0.9803 - val_loss: 0.0790 - val_accuracy: 0.9755\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0694 - accuracy: 0.9798 - val_loss: 0.0781 - val_accuracy: 0.9779\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9786 - val_loss: 0.0783 - val_accuracy: 0.9771\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0700 - accuracy: 0.9799 - val_loss: 0.0787 - val_accuracy: 0.9755\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0723 - accuracy: 0.9798 - val_loss: 0.0782 - val_accuracy: 0.9771\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0710 - accuracy: 0.9805 - val_loss: 0.0783 - val_accuracy: 0.9771\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0745 - accuracy: 0.9776 - val_loss: 0.0782 - val_accuracy: 0.9779\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9792 - val_loss: 0.0783 - val_accuracy: 0.9779\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0717 - accuracy: 0.9806 - val_loss: 0.0793 - val_accuracy: 0.9779\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9801 - val_loss: 0.0782 - val_accuracy: 0.9779\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0661 - accuracy: 0.9812 - val_loss: 0.0782 - val_accuracy: 0.9779\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9795 - val_loss: 0.0781 - val_accuracy: 0.9779\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0700 - accuracy: 0.9799 - val_loss: 0.0785 - val_accuracy: 0.9779\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0707 - accuracy: 0.9780 - val_loss: 0.0781 - val_accuracy: 0.9771\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0703 - accuracy: 0.9790 - val_loss: 0.0786 - val_accuracy: 0.9755\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0673 - accuracy: 0.9821 - val_loss: 0.0780 - val_accuracy: 0.9771\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0724 - accuracy: 0.9793 - val_loss: 0.0777 - val_accuracy: 0.9779\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0700 - accuracy: 0.9818 - val_loss: 0.0783 - val_accuracy: 0.9763\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0724 - accuracy: 0.9799 - val_loss: 0.0778 - val_accuracy: 0.9771\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0722 - accuracy: 0.9797 - val_loss: 0.0781 - val_accuracy: 0.9779\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9791 - val_loss: 0.0782 - val_accuracy: 0.9779\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0815 - accuracy: 0.9774 - val_loss: 0.0782 - val_accuracy: 0.9755\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9791 - val_loss: 0.0781 - val_accuracy: 0.9755\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9792 - val_loss: 0.0782 - val_accuracy: 0.9771\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0676 - accuracy: 0.9806 - val_loss: 0.0779 - val_accuracy: 0.9779\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0696 - accuracy: 0.9796 - val_loss: 0.0781 - val_accuracy: 0.9771\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0685 - accuracy: 0.9804 - val_loss: 0.0779 - val_accuracy: 0.9755\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0711 - accuracy: 0.9802 - val_loss: 0.0777 - val_accuracy: 0.9771\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0711 - accuracy: 0.9791 - val_loss: 0.0782 - val_accuracy: 0.9771\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9810 - val_loss: 0.0778 - val_accuracy: 0.9771\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0696 - accuracy: 0.9810 - val_loss: 0.0783 - val_accuracy: 0.9771\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9800 - val_loss: 0.0781 - val_accuracy: 0.9771\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9793 - val_loss: 0.0776 - val_accuracy: 0.9771\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0691 - accuracy: 0.9797 - val_loss: 0.0785 - val_accuracy: 0.9779\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9785 - val_loss: 0.0776 - val_accuracy: 0.9779\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 0.9808 - val_loss: 0.0777 - val_accuracy: 0.9771\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0778 - accuracy: 0.9772 - val_loss: 0.0782 - val_accuracy: 0.9755\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0736 - accuracy: 0.9803 - val_loss: 0.0775 - val_accuracy: 0.9771\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0705 - accuracy: 0.9804 - val_loss: 0.0775 - val_accuracy: 0.9771\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.9805 - val_loss: 0.0776 - val_accuracy: 0.9771\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0673 - accuracy: 0.9815 - val_loss: 0.0779 - val_accuracy: 0.9763\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.9801 - val_loss: 0.0771 - val_accuracy: 0.9763\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0713 - accuracy: 0.9779 - val_loss: 0.0779 - val_accuracy: 0.9763\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.9802 - val_loss: 0.0771 - val_accuracy: 0.9763\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 0.9782 - val_loss: 0.0775 - val_accuracy: 0.9763\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9800 - val_loss: 0.0774 - val_accuracy: 0.9763\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9787 - val_loss: 0.0781 - val_accuracy: 0.9763\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9794 - val_loss: 0.0779 - val_accuracy: 0.9771\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0668 - accuracy: 0.9823 - val_loss: 0.0778 - val_accuracy: 0.9771\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0683 - accuracy: 0.9821 - val_loss: 0.0771 - val_accuracy: 0.9763\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0749 - accuracy: 0.9771 - val_loss: 0.0772 - val_accuracy: 0.9763\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9796 - val_loss: 0.0778 - val_accuracy: 0.9763\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0704 - accuracy: 0.9795 - val_loss: 0.0778 - val_accuracy: 0.9771\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9788 - val_loss: 0.0773 - val_accuracy: 0.9771\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9790 - val_loss: 0.0775 - val_accuracy: 0.9771\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 0.9803 - val_loss: 0.0780 - val_accuracy: 0.9763\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9794 - val_loss: 0.0774 - val_accuracy: 0.9771\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 0.9809 - val_loss: 0.0776 - val_accuracy: 0.9771\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9801 - val_loss: 0.0774 - val_accuracy: 0.9763\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0732 - accuracy: 0.9799 - val_loss: 0.0774 - val_accuracy: 0.9755\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0763 - accuracy: 0.9773 - val_loss: 0.0774 - val_accuracy: 0.9771\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9790 - val_loss: 0.0778 - val_accuracy: 0.9763\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0720 - accuracy: 0.9787 - val_loss: 0.0773 - val_accuracy: 0.9763\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9782 - val_loss: 0.0776 - val_accuracy: 0.9771\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0743 - accuracy: 0.9792 - val_loss: 0.0774 - val_accuracy: 0.9771\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0641 - accuracy: 0.9818 - val_loss: 0.0776 - val_accuracy: 0.9763\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9802 - val_loss: 0.0772 - val_accuracy: 0.9771\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0693 - accuracy: 0.9804 - val_loss: 0.0776 - val_accuracy: 0.9771\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0742 - accuracy: 0.9785 - val_loss: 0.0772 - val_accuracy: 0.9771\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0668 - accuracy: 0.9815 - val_loss: 0.0775 - val_accuracy: 0.9771\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDLwbcYXYRWl",
        "outputId": "36825d64-37cd-4821-8647-d2a190c58060"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "165/165 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06676048785448074, 0.9809705018997192]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "fDfW1XQTxKH3",
        "outputId": "fe2964d0-2a26-4a57-a882-ffc0767894b8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('‘Model Loss’')\n",
        "plt.ylabel('‘Losss’')\n",
        "plt.xlabel('‘Epochs’')\n",
        "plt.yscale(\"log\")\n",
        "plt.legend(['‘train’', '‘test’'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWMk3iDc3O96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4561cb3e-00fa-4e8c-a6c3-faa71218c2a3"
      },
      "source": [
        "y_pred=model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 11378, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 11378, 8), dtype=tf.float32, name='dense_36_input'), name='dense_36_input', description=\"created by layer 'dense_36_input'\"), but it was called on an input with incompatible shape (None, 8).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saSidLOnO9-p"
      },
      "source": [
        "The threshold has been calculated by the mean prediction of each class on the validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3dH8Wpc4UOG"
      },
      "source": [
        "y_pred = (y_pred > 0.2).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAaw7FH6U8JR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5be022bb-1df3-4c25-a6aa-5d4210bc80e6"
      },
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "matrix = confusion_matrix(y_test,y_pred, labels=[1,0])\n",
        "print('Confusion matrix : \\n',matrix)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix : \n",
            " [[ 430   43]\n",
            " [  67 4715]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}